{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"BunnyVisionPro","text":"<p>BunnyVisionPro is a robot teleoperation system integrated with Apple Vision Pro as pose tracking device, specifically tailored for bimanual dexterous manipulation. The system boasts a highly modular architecture, simplifying deployment and enhancing flexibility. Key features of the system include:</p> <ul> <li>Portability: The system only requires a Vision Pro as hand pose tracking device, making it highly portable and easy to   set up.</li> <li>Scalability: The system is designed to be compatible with a wide range of robot platforms, including different robot   arms and hands.</li> <li>Containization: The server and client components of the system are containerized, ensuring easy deployment and   management.</li> </ul> <p>Begin using BunnyVisionPro by following the simple installation guide.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you find this codebase helpful in your work, please consider cite:</p> <pre><code>@article{bunny-visionpro,\n  author  = {Runyu Ding, Yuzhe Qin, Jiyue Zhu, Chengzhe Jia, Shiqi Yang, Ruihan Yang, Xiaojuan Qi, and Xiaolong Wang},\n  title   = {Bunny-VisionPro: Bimanual Dexterous Teleoperation with Real-Time Retargeting using Vision Pro},\n year   = {2024},\n}\n</code></pre>"},{"location":"#acknowledge","title":"Acknowledge","text":"<p>Our code is built upon VisionProTeleop, dex-retargeting, sim-web-visualizer. We thank all these authors for their nicely open sourced code and their great contributions to the community.</p>"},{"location":"advanced/initialization/","title":"Teleoperation Initialization","text":"<p>Teleoperation systems map human movements to robotic actions. For instance, advancing your right hand by 0.1 meters should correspondingly move the robot's right end effector forward by the same distance. Establishing a clear definition of coordinate system for both human and robot through an initialization step is crucial to accurately translating human motion to robot in three-dimensional space.</p>"},{"location":"advanced/initialization/#calibration-between-human-and-robot","title":"Calibration Between Human and Robot","text":""},{"location":"advanced/initialization/#initialization-process","title":"Initialization Process","text":"<p>During the initialization phase, we establish a three-dimensional frame in both human and robot coordinate systems, referred to as the initial human frame and the initial robot frame, respectively. Movements by the human operator are measured relative to the initial human frame, and the robot mimics these relative movements within its corresponding initial robot frame.</p>"},{"location":"advanced/initialization/#system-configuration","title":"System Configuration","text":"<p>The positions and orientations of these initial frames are configured via the <code>TeleopClient</code> API as shown below:</p> <pre><code>import numpy as np\nfrom bunny_teleop.init_config import BimanualAlignmentMode\n\n\nclass TeleopClient:\n  def send_init_config(\n    self,\n    *,\n    robot_base_pose: Tuple[np.ndarray, np.ndarray],\n    init_qpos: Tuple[np.ndarray, np.ndarray],\n    joint_names: Tuple[List[str], List[str]],\n    align_gravity_dir=True,\n    bimanual_alignment_mode=BimanualAlignmentMode.ALIGN_CENTER,\n  ):\n    # Implementation skipped for doc purpose\n    pass\n</code></pre> <p>Checking Initialization Status</p> <p>Use <code>teleop_client.started</code> or <code>teleop_client.wait_for_server_start()</code> to confirm if the initialization has completed.</p>"},{"location":"advanced/initialization/#initializing-the-robot-frame","title":"Initializing the Robot Frame","text":"<p>Upon successful operation of the <code>bunny_teleop_server</code>, the teleop initialization is triggered by the <code>send_init_config</code> API call. This function requires the initial pose of the robot (<code>init_qpos</code>), which represents the joint positions for both the left and right robotic arms. The teleop server computes the end effector poses using forward kinematics to determine the initial robot frame.</p> <p>Be Careful about Joint Orders</p> <p>Ensure the joint names are correctly specified as the teleop server may parse the robot model differently, affecting the joint order.</p>"},{"location":"advanced/initialization/#initializing-the-human-frame","title":"Initializing the Human Frame","text":"<p>Post the API call, the VisionPro system begins tracking the operator's hand poses. To mitigate noise in hand pose estimation, an average pose is calculated from 200 frames following the initialization call. The initialization completes once these poses are processed, allowing the teleop server to begin streaming commands.</p> <p>Good Hand Poses are Important for Initialization</p> <p>The frame counter resets to 0 if the operator's hands are not held still or if the fingers are not spread out flat. If the teleop_server has not started within 5 seconds after initialization, check the position and condition of both  hands. </p> <p>An example of a proper hand pose is shown below:</p> <p></p>"},{"location":"advanced/initialization/#bimanual-alignment-modes","title":"Bimanual Alignment Modes","text":""},{"location":"advanced/initialization/#overview","title":"Overview","text":"<p>In the tutorial above, we skip how to determine the initial frames for the left and right hands. Essentially, we can treat each hand as a separate entity with its own frame, similar to individual robots, or use a single frame for controlling both hands in bimanual operations. Depending on the task, different configurations might be preferable. Our system allows users to select the desired mode through the <code>bimanual_alignment_mode</code> variable in the <code>send_init_config</code> function, offering various options to best suit specific task requirements.</p> <pre><code>class BimanualAlignmentMode(Enum):\n  ALIGN_CENTER = 0\n  ALIGN_LEFT = 1\n  ALIGN_RIGHT = 2\n  ALIGN_SEPARATELY = 3\n</code></pre>"},{"location":"advanced/initialization/#mode-descriptions","title":"Mode Descriptions","text":"<ul> <li>ALIGN_SEPARATELY: Treats each arm as an independent entity, ideal for tasks requiring distinct movements.</li> <li>ALIGN_CENTER: Calculates a center between the two robot end effectors, aligning this with the midpoint between   the human hands.</li> <li>ALIGN_LEFT and ALIGN_RIGHT: Focuses on one hand's position and orientation, useful for tasks prioritizing one   side.</li> </ul> <p>Global Pose of Robot Base</p> <p>To provide the teleoperation server with the positions of the two robot arms, the <code>robot_base_pose</code> variable is used.  This variable, a tuple consisting of two 7-dimensional numpy arrays, specifies the position and orientation (using the quaternion wxyz convention) of each robot's base.</p> <p>Danger</p> <p>For modes except <code>ALIGN_SEPARATELY</code> Robot arms may move instantly after initialization is finished even if the human operator keeps static.This can be dangers on real robot if you are not aware what will happen after initialization. Try first on our simulation version before deploying on the real robot.</p>"},{"location":"advanced/visualization/","title":"Visualization Tools","text":"<p>To provide an intuitive user interface of the initialization and teleoperation, a web-based GUI visualizes these processes in real-time. This feature utilizes the sim_web_visualizer.</p>"},{"location":"advanced/visualization/#3d-cursor-for-initialization","title":"3D Cursor for Initialization","text":"<p>During initialization, a large 3D cursor displayed on the interface becomes increasingly transparent to reflect progress, transitioning to two smaller 3D gizmos indicating the end effector positions upon completion.</p> <code>ALIGN_CENTER</code> <code>ALIGN_LEFT</code> <code>ALIGN_RIGHT</code> <code>ALIGN_SEPARATELY</code>"},{"location":"advanced/visualization/#gizmo-for-moving-robot","title":"Gizmo for Moving Robot","text":"<p>After initialization, the robot will begin moving inside the web visualizer. The two small gizmo shows the end effector pose from human.</p> <p></p>"},{"location":"getstarted/install/","title":"Installation","text":"<p>BunnyVisionPro is designed as a distributed system to facilitate robot teleoperation. The system consists of a server and a client that communicate via data streaming, leveraging the Apple Vision Pro as hand pose tracking device. To interact with Vision Pro, download the Tracking Streamer app on your device.</p> <p>The server can be installed and run inside a Docker container, while the client is super  light-weight can be installed using pip.</p>"},{"location":"getstarted/install/#server-installation","title":"Server Installation","text":"<p>Before running the server code inside a Docker container, you need to either pull an existing Docker image or build one yourself.</p>"},{"location":"getstarted/install/#pulling-an-existing-docker-image","title":"Pulling an Existing Docker Image","text":"<p>For quick setup, pull an existing Docker image from Docker Hub using the following command:</p> <pre><code>docker pull yzqin/bunny_teleop_server\n</code></pre>"},{"location":"getstarted/install/#building-a-docker-image-from-a-dockerfile-optional","title":"Building a Docker Image from a Dockerfile (Optional)","text":"<p>If you need a custom setup, you can also build your own Docker image using the provided Dockerfile.</p> <pre><code>git clone https://github.com/Dingry/bunny_teleop_server.git\ncd bunny_teleop_server/docker/minimal\n\ndocker build -t bunny_teleop_server .\n</code></pre>"},{"location":"getstarted/install/#client-installation","title":"Client Installation","text":"<p>The client can be easily installed using Python's pip package manager:</p> <pre><code>pip install bunny_teleop\n</code></pre>"},{"location":"getstarted/tips/","title":"Tips and Troubleshooting","text":""},{"location":"getstarted/tips/#tips-for-initialization","title":"Tips for Initialization","text":"Good Human Hand Pose for Initialization <p>Extend your arms forward with your palms facing downwards, maintaining a slight separation between your hands. Keep your arms and hands in the same position until the calibration is completed. An example can be found here.</p> Aligning Gravity Direction by Default <p>During this process, the system automatically aligns with the gravity direction of your hands (<code>align_gravity_dir</code> set to <code>True</code>). This means that one of the xyz axis for initial human frame is always aligned with gravity direction. </p>"},{"location":"getstarted/tips/#tips-for-teleoperation","title":"Tips for Teleoperation","text":"Initial Use Caution <p>When operating the system for the first time, move your arms slowly to familiarize yourself with its response. The robots have velocity limits which can introduce latency, so slow movements help avoid potential collisions.</p> Calibration and Positioning <p>Hand position calibration is based on the world coordinate system and largely independent of the Vision Pro\u2019s location. To reach positions beyond your immediate action space, adjust your stance (step back, forward, left, or right)  without changing the pose of your hands, preventing unintended hand movements.</p> Hand Pose Strategy <p>Typically, keep your hands parallel. However, for tasks requiring different heights, start with one hand lower during calibration\u2014this allows more movement range upward.  For example, lower your right hand initially if you need it to move higher during operation.</p> Visibility for Accurate Tracking <p>Ensure all fingers are fully visible to the Vision Pro\u2019s camera for precise hand tracking. Partial visibility can result in inaccurate tracking, causing oscillations or unintended robot finger movements.</p>"},{"location":"getstarted/tips/#troubleshooting","title":"Troubleshooting","text":"IP of Vision Pro <p>If the IP address displayed in the Tracking Streamer app is incorrect or appears as an IPv6 address, navigate to the settings menu on your Vision Pro device: <code>Settings &gt; WiFi &gt; Details &gt; IP Configuration</code>. Ensure you obtain the correct IPv4 address from this menu.</p> Restarting the Teleop Server After Extended Use <p>The teleoperation <code>robot_server</code> is designed to operate continuously, refreshing automatically with each new <code>InitializationConfig</code> received from the client. However, due to the unpredictable nature of communication, the server may occasionally fail after prolonged use. If you observe multiple error messages in the server tab, terminate the server process and restart the <code>robot_server</code>.  Restart the <code>vision_server</code> only if the connection between the computer and VisionPro is disrupted.</p>"},{"location":"getstarted/usage/","title":"Basic Usage","text":"<p>This guide covers the setup and operation of the BunnyVisionPro server and client. Although the server and client can be set up on different machines, for simplicity, this tutorial assumes they are on the same computer.</p>"},{"location":"getstarted/usage/#bunny-teleoperation-server-setup","title":"Bunny Teleoperation Server Setup","text":""},{"location":"getstarted/usage/#1-start-the-server-docker","title":"1. Start the Server Docker","text":"<p>Execute the following command to run the teleoperation server inside a Docker container:</p> <pre><code>docker run -it --net host --name bunny_teleop_server -v yzqin/bunny_teleop_server bash\n</code></pre>"},{"location":"getstarted/usage/#2-network-configuration","title":"2. Network Configuration","text":"<p>Ensure that the server, client, and Vision Pro are connected to the same Local Area Network (LAN).</p>"},{"location":"getstarted/usage/#3-launch-tracking-streamer-app","title":"3. Launch Tracking Streamer App","text":"<p>Open the Tracking Streamer app on your Vision Pro device and note the IPv4 address shown on the screen.</p>"},{"location":"getstarted/usage/#4-configure-ip-in-docker","title":"4. Configure IP in Docker","text":"<p>Update the <code>visionpro_config.yml</code> file inside the Docker container to include the IPv4 address of your Apple Vision Pro:</p> <pre><code>cameras:\n  - visionpro:\n      avp_ip: &lt;avp_ip&gt;\n</code></pre> <p>You can edit this file using a terminal-based editor such as <code>nano</code>, <code>vim</code>, or <code>emacs</code> inside docker. For example:</p> <pre><code>vim /server/bunny_teleop_server/configs/camera_config/visionpro_config.yml\n</code></pre>"},{"location":"getstarted/usage/#5-start-server-nodes-inside-docker","title":"5. Start Server Nodes Inside Docker","text":"<p>Start the vision node to stream hand pose data from VisionPro:</p> <pre><code>run_vision_server -c /server/bunny_teleop_server/configs/camera_config/visionpro_config.yml\n</code></pre> <p>Then, start the robot node for teleoperation:</p> <pre><code>run_robot_server -c /server/bunny_teleop_server/configs/camera_config/visionpro_config.yml -k /server/bunny_teleop_server/configs/kinematics_config/bimanual_xarm7_ability.yml --comm /server/bunny_teleop_server/configs/communication_config/sim_web_visualizer.yml\n</code></pre> <p>Use two terminal tabs for these servers, which can be managed using <code>tmux</code> inside Docker or by opening another terminal tab with:</p> <pre><code>docker exec -it bunny_teleop_server bash\n</code></pre>"},{"location":"getstarted/usage/#6-web-visualization","title":"6. Web Visualization","text":"<p>Open a web browser and navigate to http://127.0.0.1:7000/static/. You should see the teleoperation interface with both left and robot arms overlapped at the world origin. This is because the teleop server will not know the pose of left and right robot base in the world coordinate until the client informs it.</p> <p></p> <p>Tip</p> <p>To access the web visualization from a different machine, replace <code>127.0.0.1</code> with the IP address of the machine running the teleop server.</p>"},{"location":"getstarted/usage/#bunny-teleoperation-client-setup","title":"Bunny Teleoperation Client Setup","text":""},{"location":"getstarted/usage/#starting-the-minimal-teleop-client","title":"Starting the Minimal Teleop Client","text":"<p>To initiate the teleoperation client, follow these steps:</p> <pre><code>git clone https://github.com/Dingry/BunnyVisionPro\ncd BunnyVisionPro\npython examples/minimal/minimal.py\n</code></pre> <p>Upon starting the teleop client, it immediately transmits robot information to the server. You should then observe the initial state on the web visualization interface:</p> <p></p> <p>More information about initialization can be found in Teleoperation Initialization</p> <p>Note</p> <p>Once the client is running, if the hand pose is accurately detected, the initialization completes quickly, and the robots will begin to mimic your hand movements. You may not have a chance to the see the figure above. Don't worry, this indicates that the system is functioning correctly.</p> <p>Now you can control the virtual robot arms inside the web visualizer with your hand motion.</p>"},{"location":"system/overview/","title":"System Overview","text":""}]}